import streamlit as st
import pandas as pd
from main import analyze_webpage_links, get_all_links, is_professor_webpage, get_research_interests, get_client
import os
import tempfile
import concurrent.futures
import time
import requests
import re
from bs4 import BeautifulSoup

st.set_page_config(page_title="æ•™æˆç ”ç©¶å…´è¶£åˆ†æå™¨ ğŸ“", layout="wide")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡
if 'professor_results' not in st.session_state:
    st.session_state.professor_results = None
if 'api_key' not in st.session_state:
    st.session_state.api_key = None
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'similarity_results' not in st.session_state:
    st.session_state.similarity_results = None

def calculate_similarity(prof_interests, user_interests, api_key):
    """ä½¿ç”¨LLMè®¡ç®—æ•™æˆç ”ç©¶å…´è¶£ä¸ç”¨æˆ·å…´è¶£çš„ç›¸ä¼¼åº¦"""
    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        current_client = get_client(api_key)
            
        llm_response = current_client.chat.completions.create(
            model="doubao-1-5-pro-32k-250115",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯åŒ¹é…ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†ææ•™æˆçš„ç ”ç©¶å…´è¶£ä¸ç”¨æˆ·çš„ç ”ç©¶å…´è¶£ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œç»™å‡º0-100çš„åˆ†æ•°å’Œè¯¦ç»†è§£é‡Šã€‚"},
                {"role": "user", "content": f"è¯·åˆ†æä»¥ä¸‹æ•™æˆçš„ç ”ç©¶å…´è¶£ä¸ç”¨æˆ·çš„ç ”ç©¶å…´è¶£ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚ç»™å‡º0-100çš„ç›¸ä¼¼åº¦åˆ†æ•°å’Œè¯¦ç»†è§£é‡Šã€‚\n\næ•™æˆç ”ç©¶å…´è¶£: {prof_interests}\n\nç”¨æˆ·ç ”ç©¶å…´è¶£: {user_interests}"}
            ]
        )
        return llm_response.choices[0].message.content.strip()
    except Exception as e:
        return f"åˆ†æç›¸ä¼¼åº¦æ—¶å‡ºé”™: {str(e)}"

def extract_similarity_score(similarity_text):
    """ä»ç›¸ä¼¼åº¦æ–‡æœ¬ä¸­æå–åˆ†æ•°"""
    try:
        # å°è¯•æŸ¥æ‰¾æ•°å­—æ¨¡å¼ï¼Œä¾‹å¦‚"ç›¸ä¼¼åº¦ï¼š85åˆ†"æˆ–"ç›¸ä¼¼åº¦åˆ†æ•°ï¼š85/100"
        matches = re.findall(r'(\d+)(?:/100|\s*åˆ†|\s*ç‚¹)', similarity_text)
        if matches:
            return int(matches[0])
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ¼å¼åŒ–çš„åˆ†æ•°ï¼Œå°è¯•æŸ¥æ‰¾å•ç‹¬çš„æ•°å­—
        matches = re.findall(r'(?<!\d)\b(\d{1,3})\b(?!\d)', similarity_text)
        if matches:
            # è¿‡æ»¤æ‰ä¸å¤ªå¯èƒ½æ˜¯åˆ†æ•°çš„æ•°å­—ï¼ˆå¤ªå°æˆ–å¤ªå¤§ï¼‰
            possible_scores = [int(m) for m in matches if 0 <= int(m) <= 100]
            if possible_scores:
                return max(possible_scores)  # è¿”å›æœ€å¯èƒ½çš„åˆ†æ•°
        
        return 0  # é»˜è®¤å€¼
    except Exception:
        return 0  # å‡ºé”™æ—¶è¿”å›é»˜è®¤å€¼

def analyze_with_progress(start_url, api_key, max_links=30, max_workers=5):
    """åœ¨ç•Œé¢ä¸Šæ˜¾ç¤ºåˆ†æè¿›åº¦çš„å‡½æ•°"""
    if not api_key:
        st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ è®¾ç½®APIå¯†é’¥")
        return pd.DataFrame(columns=["URL", "Is Professor Page", "Research Interests"])
    
    # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
    client = get_client(api_key)
    
    # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºç»„ä»¶
    progress_container = st.empty()
    progress_text = st.empty()
    progress_bar = st.progress(0)
    
    # æ­¥éª¤1: è·å–æ‰€æœ‰é“¾æ¥
    progress_text.text("ç¬¬1æ­¥: ğŸ” è·å–é“¾æ¥ä¸­...")
    links = get_all_links(start_url)[:max_links]
    if not links:
        progress_text.text("âŒ æ— æ³•è·å–ä»»ä½•é“¾æ¥ï¼Œè¯·æ£€æŸ¥URLæ˜¯å¦æ­£ç¡®")
        return pd.DataFrame(columns=["URL", "Is Professor Page", "Research Interests"])
    
    progress_container.info(f"ğŸ”— å…±æ‰¾åˆ° {len(links)} ä¸ªé“¾æ¥ï¼Œå‡†å¤‡åˆ†æ")
    
    # æ­¥éª¤2: åˆ†ææ¯ä¸ªé“¾æ¥
    progress_text.text("ç¬¬2æ­¥: ğŸ” åˆ†æé“¾æ¥ä¸­...")
    results = []
    session = requests.Session()
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†é“¾æ¥
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_link = {executor.submit(process_link_with_feedback, link, session, client): link for link in links}
        
        completed = 0
        for future in concurrent.futures.as_completed(future_to_link):
            link = future_to_link[future]
            try:
                result = future.result()
                if result:
                    results.append(result)
                    # æ›´æ–°çŠ¶æ€ä¿¡æ¯
                    if result["Is Professor Page"] == "Yes":
                        progress_container.success(f"âœ… æ‰¾åˆ°æ•™æˆé¡µé¢: {link}")
            except Exception as e:
                progress_container.error(f"âŒ å¤„ç† {link} æ—¶å‡ºé”™: {str(e)}")
                results.append({
                    "URL": link,
                    "Is Professor Page": "Error",
                    "Research Interests": f"Error: {str(e)}"
                })
            
            # æ›´æ–°è¿›åº¦æ¡
            completed += 1
            progress = completed / len(links)
            progress_bar.progress(progress)
            progress_text.text(f"ç¬¬2æ­¥: ğŸ” åˆ†æé“¾æ¥ä¸­... ({completed}/{len(links)})")
    
    # åˆ›å»ºDataFrame
    df = pd.DataFrame(results)
    
    # åˆ†æå®Œæˆ
    professor_count = sum(1 for r in results if r["Is Professor Page"] == "Yes")
    progress_container.success(f"ğŸ‰ åˆ†æå®Œæˆ! å…±æ‰¾åˆ° {professor_count} ä¸ªæ•™æˆé¡µé¢ (æ€»å…±åˆ†æäº† {len(results)} ä¸ªé“¾æ¥)")
    progress_text.empty()
    progress_bar.empty()
    
    # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
    st.session_state.analysis_results = df
    # æå–æ•™æˆé¡µé¢
    st.session_state.professor_results = df[df["Is Professor Page"] == "Yes"]
    
    return df

def process_link_with_feedback(link, session, client):
    """å¤„ç†å•ä¸ªé“¾æ¥ï¼Œç”¨äºå¸¦è¿›åº¦æ˜¾ç¤ºçš„ç‰ˆæœ¬"""
    try:
        is_professor = is_professor_webpage(link, session, client)
        if is_professor:
            research_interests = get_research_interests(link, session, client)
            return {
                "URL": link,
                "Is Professor Page": "Yes",
                "Research Interests": research_interests
            }
        else:
            return {
                "URL": link,
                "Is Professor Page": "No",
                "Research Interests": ""
            }
    except Exception as e:
        return {
            "URL": link,
            "Is Professor Page": "Error",
            "Research Interests": f"Error: {str(e)}"
        }

# æ·»åŠ ä¸€ä¸ªå‡½æ•°æ¥æ˜¾ç¤ºç»“æœï¼Œé¿å…ä»£ç é‡å¤
def display_results(results_df):
    """æ˜¾ç¤ºç›¸ä¼¼åº¦ç»“æœ"""
    if results_df is None or len(results_df) == 0:
        st.warning("âš ï¸ æ²¡æœ‰ç»“æœå¯æ˜¾ç¤º")
        return
        
    for _, row in results_df.iterrows():
        with st.expander(f"ğŸ”— ç›¸ä¼¼åº¦ {row['Score']}åˆ† - URL: {row['URL']}"):
            st.markdown("#### ğŸ‘¨â€ğŸ« æ•™æˆç ”ç©¶å…´è¶£")
            st.write(row["Research Interests"])
            st.markdown("#### ğŸ“Š ç›¸ä¼¼åº¦åˆ†æ")
            st.write(row["Similarity Analysis"])

def main():
    st.title("ğŸ“ æ•™æˆç ”ç©¶å…´è¶£åˆ†æå™¨")
    
    # APIè®¾ç½®åœ¨ä¾§è¾¹æ 
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")
        api_key = st.text_input("è¾“å…¥APIå¯†é’¥ï¼ˆå¿…å¡«ï¼‰", type="password")
        if api_key:
            st.session_state.api_key = api_key
            st.success("âœ… APIå¯†é’¥å·²è®¾ç½®")
        else:
            st.warning("âš ï¸ è¯·è¾“å…¥APIå¯†é’¥æ‰èƒ½ä½¿ç”¨åˆ†æåŠŸèƒ½")
    
    tab1, tab2 = st.tabs(["ğŸ” ç½‘ç«™åˆ†æ", "ğŸ”„ å…´è¶£åŒ¹é…"])
    
    with tab1:
        st.header("ğŸ“Š åˆ†æå¤§å­¦ç½‘ç«™ä¸Šçš„æ•™æˆé¡µé¢")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            start_url = st.text_input("è¾“å…¥èµ·å§‹URL", "https://journalism.uiowa.edu/people")
        
        with col2:
            max_links = st.number_input("æœ€å¤§åˆ†æé“¾æ¥æ•°", min_value=10, max_value=500, value=30, step=10)
            max_workers = st.number_input("å·¥ä½œçº¿ç¨‹æ•°", min_value=1, max_value=10, value=5, step=1)
        
        if st.button("ğŸš€ å¼€å§‹åˆ†æ"):
            if not st.session_state.api_key:
                st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ è®¾ç½®APIå¯†é’¥")
            else:
                # ä½¿ç”¨åŒ…å«è¿›åº¦æ˜¾ç¤ºçš„åˆ†æå‡½æ•°
                results_df = analyze_with_progress(start_url, st.session_state.api_key, max_links=max_links, max_workers=max_workers)
                
                # ä¿å­˜ç»“æœåˆ°ä¸´æ—¶æ–‡ä»¶
                temp_dir = tempfile.mkdtemp()
                csv_path = os.path.join(temp_dir, "professor_analysis_results.csv")
                results_df.to_csv(csv_path, index=False)
                
                # æ˜¾ç¤ºæ‰€æœ‰ç»“æœ
                st.subheader("ğŸ“‹ åˆ†æç»“æœ")
                st.dataframe(results_df)
                
                # æ˜¾ç¤ºæ•™æˆé¡µé¢
                professor_pages = results_df[results_df["Is Professor Page"] == "Yes"]
                if not professor_pages.empty:
                    st.subheader("ğŸ‘¨â€ğŸ« æ‰¾åˆ°çš„æ•™æˆé¡µé¢")
                    st.dataframe(professor_pages)
                    
                    # æä¾›ä¸‹è½½é“¾æ¥
                    with open(csv_path, "rb") as file:
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½åˆ†æç»“æœ",
                            data=file,
                            file_name="professor_analysis_results.csv",
                            mime="text/csv"
                        )
                else:
                    st.warning("âš ï¸ æœªæ‰¾åˆ°æ•™æˆé¡µé¢")
        
        # æ˜¾ç¤ºä¼šè¯ä¸­ä¿å­˜çš„ç»“æœ
        elif st.session_state.analysis_results is not None:
            st.subheader("ğŸ“‹ ä¸Šæ¬¡åˆ†æç»“æœ")
            st.dataframe(st.session_state.analysis_results)
            
            if st.session_state.professor_results is not None and not st.session_state.professor_results.empty:
                st.subheader("ğŸ‘¨â€ğŸ« æ‰¾åˆ°çš„æ•™æˆé¡µé¢")
                st.dataframe(st.session_state.professor_results)
                
                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¾›ä¸‹è½½
                temp_dir = tempfile.mkdtemp()
                csv_path = os.path.join(temp_dir, "professor_analysis_results.csv")
                st.session_state.analysis_results.to_csv(csv_path, index=False)
                
                with open(csv_path, "rb") as file:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½åˆ†æç»“æœ",
                        data=file,
                        file_name="professor_analysis_results.csv",
                        mime="text/csv"
                    )
    
    with tab2:
        st.header("ğŸ”„ ç ”ç©¶å…´è¶£ç›¸ä¼¼åº¦åŒ¹é…")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•™æˆç»“æœ
        professor_pages = None
        if st.session_state.professor_results is not None and not st.session_state.professor_results.empty:
            professor_pages = st.session_state.professor_results
            has_professors = True
        else:
            st.info("â„¹ï¸ è¯·å…ˆåœ¨'ğŸ” ç½‘ç«™åˆ†æ'æ ‡ç­¾ä¸­åˆ†æä¸€ä¸ªç½‘ç«™ä»¥è·å–æ•™æˆç ”ç©¶å…´è¶£")
            professor_pages = pd.DataFrame(columns=["URL", "Is Professor Page", "Research Interests"])
            has_professors = False
        
        # ç”¨æˆ·è¾“å…¥ç ”ç©¶å…´è¶£
        user_interests = st.text_area("âœï¸ è¾“å…¥æ‚¨çš„ç ”ç©¶å…´è¶£ï¼ˆè¯·è¯¦ç»†æè¿°æ‚¨æ„Ÿå…´è¶£çš„ç ”ç©¶é¢†åŸŸã€æ–¹æ³•å’Œä¸»é¢˜ï¼‰", height=150)
        has_interests = bool(user_interests.strip())
        
        # å§‹ç»ˆæ˜¾ç¤ºæŒ‰é’®ï¼Œä½†æ ¹æ®æ¡ä»¶ç¦ç”¨
        col1, col2 = st.columns([3, 1])
        with col1:
            calc_button = st.button("ğŸ” è®¡ç®—ç›¸ä¼¼åº¦", disabled=not has_professors or not has_interests)
            if not has_professors and not has_interests:
                st.caption("è¯·å…ˆåˆ†æç½‘ç«™å¹¶è¾“å…¥ç ”ç©¶å…´è¶£")
            elif not has_professors:
                st.caption("è¯·å…ˆåˆ†æç½‘ç«™ä»¥è·å–æ•™æˆæ•°æ®")
            elif not has_interests:
                st.caption("è¯·è¾“å…¥æ‚¨çš„ç ”ç©¶å…´è¶£")
        with col2:
            sort_button = st.button("ğŸ“Š æ’åºç»“æœ", disabled="similarity_results" not in st.session_state or st.session_state.similarity_results is None)
            if "similarity_results" not in st.session_state or st.session_state.similarity_results is None:
                st.caption("è¯·å…ˆè®¡ç®—ç›¸ä¼¼åº¦")
        
        # å¤„ç†è®¡ç®—ç›¸ä¼¼åº¦æŒ‰é’®
        if calc_button and has_professors and has_interests:
            if not st.session_state.api_key:
                st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ è®¾ç½®APIå¯†é’¥")
            else:
                st.subheader("ğŸ“Š ç›¸ä¼¼åº¦åˆ†æç»“æœ")
                
                # æ˜¾ç¤ºè¿›åº¦æŒ‡ç¤ºå™¨
                progress_container = st.empty()
                progress_bar = st.progress(0)
                progress_text = st.empty()
                
                # ä¸ºæ¯ä½æ•™æˆè®¡ç®—ç›¸ä¼¼åº¦
                results = []
                total_professors = len(professor_pages)
                
                for i, (_, row) in enumerate(professor_pages.iterrows()):
                    # æ›´æ–°è¿›åº¦
                    progress = (i) / total_professors
                    progress_bar.progress(progress)
                    progress_text.text(f"â³ æ­£åœ¨è®¡ç®—ç¬¬ {i+1}/{total_professors} ä½æ•™æˆçš„ç›¸ä¼¼åº¦...")
                    progress_container.info(f"ğŸ”„ åˆ†æä¸­: {row['URL']}")
                    
                    # è®¡ç®—ç›¸ä¼¼åº¦
                    similarity = calculate_similarity(row["Research Interests"], user_interests, st.session_state.api_key)
                    # æå–ç›¸ä¼¼åº¦åˆ†æ•°
                    similarity_score = extract_similarity_score(similarity)
                    
                    results.append({
                        "URL": row["URL"],
                        "Research Interests": row["Research Interests"],
                        "Similarity Analysis": similarity,
                        "Score": similarity_score
                    })
                
                # å®Œæˆæ‰€æœ‰è®¡ç®—
                progress_bar.progress(1.0)
                progress_text.text("âœ… ç›¸ä¼¼åº¦è®¡ç®—å®Œæˆ!")
                time.sleep(0.5)  # çŸ­æš‚æ˜¾ç¤ºå®ŒæˆçŠ¶æ€
                progress_bar.empty()
                progress_text.empty()
                progress_container.empty()
                
                # ä¿å­˜ç»“æœåˆ°ä¼šè¯çŠ¶æ€
                st.session_state.similarity_results = pd.DataFrame(results)
                
                # æ˜¾ç¤ºç»“æœ
                display_results(st.session_state.similarity_results)
        
        # å¤„ç†æ’åºæŒ‰é’®
        elif sort_button and "similarity_results" in st.session_state and st.session_state.similarity_results is not None:
            # æŒ‰ç›¸ä¼¼åº¦åˆ†æ•°æ’åºç»“æœ
            sorted_results = st.session_state.similarity_results.sort_values(by="Score", ascending=False)
            
            st.subheader("ğŸ“Š æ’åºåçš„ç›¸ä¼¼åº¦åˆ†æç»“æœ")
            display_results(sorted_results)
            
        # å¦‚æœå·²æœ‰ç»“æœä½†æœªç‚¹å‡»ä»»ä½•æŒ‰é’®ï¼Œæ˜¾ç¤ºä¹‹å‰çš„ç»“æœ
        elif "similarity_results" in st.session_state and st.session_state.similarity_results is not None:
            st.subheader("ğŸ“Š ä¸Šæ¬¡ç›¸ä¼¼åº¦åˆ†æç»“æœ")
            display_results(st.session_state.similarity_results)

if __name__ == "__main__":
    main() 