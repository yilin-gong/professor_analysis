import streamlit as st
import pandas as pd
from main import (
    analyze_webpage_links,
    adaptive_analysis_with_intelligent_params,
    intelligent_parameter_estimation,
    get_client
)
import os
import tempfile
import concurrent.futures
import time
import requests
import re
from bs4 import BeautifulSoup
import logging

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

st.set_page_config(page_title="æ•™æˆç ”ç©¶å…´è¶£åˆ†æå™¨ ğŸ“", layout="wide")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡
if "professor_results" not in st.session_state:
    st.session_state.professor_results = None
if "api_key" not in st.session_state:
    st.session_state.api_key = None
if "analysis_results" not in st.session_state:
    st.session_state.analysis_results = None
if "similarity_results" not in st.session_state:
    st.session_state.similarity_results = None


def render_keyword_tag(keyword: str) -> str:
    """æ¸²æŸ“ä¸»é¢˜è‡ªé€‚åº”çš„å…³é”®è¯æ ‡ç­¾"""
    # ä½¿ç”¨CSSå˜é‡å’Œæ›´å¥½çš„é¢œè‰²æ–¹æ¡ˆï¼Œæ”¯æŒæ˜äº®å’Œå¤œé—´ä¸»é¢˜
    style = """
    background-color: var(--background-color, rgba(59, 130, 246, 0.1)); 
    color: var(--text-color, #1e40af); 
    border: 1px solid var(--border-color, rgba(59, 130, 246, 0.3));
    padding: 2px 8px; 
    margin: 2px; 
    border-radius: 12px; 
    display: inline-block;
    font-size: 0.85em;
    font-weight: 500;
    """
    
    # æ·»åŠ CSSå˜é‡å®šä¹‰ï¼Œé€‚é…ä¸åŒä¸»é¢˜
    css_vars = """
    <style>
    :root {
        --background-color: rgba(59, 130, 246, 0.1);
        --text-color: #1e40af;
        --border-color: rgba(59, 130, 246, 0.3);
    }
    @media (prefers-color-scheme: dark) {
        :root {
            --background-color: rgba(59, 130, 246, 0.2);
            --text-color: #93c5fd;
            --border-color: rgba(59, 130, 246, 0.4);
        }
    }
    /* Streamlitå¤œé—´æ¨¡å¼å…¼å®¹ */
    .stApp[data-theme="dark"] {
        --background-color: rgba(59, 130, 246, 0.2);
        --text-color: #93c5fd;
        --border-color: rgba(59, 130, 246, 0.4);
    }
    </style>
    """
    
    return f"{css_vars}<span style='{style}'>{keyword}</span>"


def calculate_similarity(prof_interests, user_interests, api_key):
    """ä½¿ç”¨LLMè®¡ç®—æ•™æˆç ”ç©¶å…´è¶£ä¸ç”¨æˆ·å…´è¶£çš„ç›¸ä¼¼åº¦"""
    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        current_client = get_client(api_key)

        llm_response = current_client.chat.completions.create(
            model="doubao-1-5-pro-32k-250115",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯åŒ¹é…ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†ææ•™æˆçš„ç ”ç©¶å…´è¶£ä¸ç”¨æˆ·çš„ç ”ç©¶å…´è¶£ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œç»™å‡º0-100çš„åˆ†æ•°å’Œè¯¦ç»†è§£é‡Šã€‚",
                },
                {
                    "role": "user",
                    "content": f"è¯·åˆ†æä»¥ä¸‹æ•™æˆçš„ç ”ç©¶å…´è¶£ä¸ç”¨æˆ·çš„ç ”ç©¶å…´è¶£ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚ç»™å‡º0-100çš„ç›¸ä¼¼åº¦åˆ†æ•°å’Œè¯¦ç»†è§£é‡Šã€‚\n\næ•™æˆç ”ç©¶å…´è¶£: {prof_interests}\n\nç”¨æˆ·ç ”ç©¶å…´è¶£: {user_interests}",
                },
            ],
        )
        return llm_response.choices[0].message.content.strip()
    except Exception as e:
        return f"åˆ†æç›¸ä¼¼åº¦æ—¶å‡ºé”™: {str(e)}"


def extract_similarity_score(similarity_text):
    """ä»ç›¸ä¼¼åº¦æ–‡æœ¬ä¸­æå–åˆ†æ•°"""
    try:
        # å°è¯•æŸ¥æ‰¾æ•°å­—æ¨¡å¼ï¼Œä¾‹å¦‚"ç›¸ä¼¼åº¦ï¼š85åˆ†"æˆ–"ç›¸ä¼¼åº¦åˆ†æ•°ï¼š85/100"
        matches = re.findall(r"(\d+)(?:/100|\s*åˆ†|\s*ç‚¹)", similarity_text)
        if matches:
            return int(matches[0])

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ¼å¼åŒ–çš„åˆ†æ•°ï¼Œå°è¯•æŸ¥æ‰¾å•ç‹¬çš„æ•°å­—
        matches = re.findall(r"(?<!\d)\b(\d{1,3})\b(?!\d)", similarity_text)
        if matches:
            # è¿‡æ»¤æ‰ä¸å¤ªå¯èƒ½æ˜¯åˆ†æ•°çš„æ•°å­—ï¼ˆå¤ªå°æˆ–å¤ªå¤§ï¼‰
            possible_scores = [int(m) for m in matches if 0 <= int(m) <= 100]
            if possible_scores:
                return max(possible_scores)  # è¿”å›æœ€å¯èƒ½çš„åˆ†æ•°

        return 0  # é»˜è®¤å€¼
    except Exception:
        return 0  # å‡ºé”™æ—¶è¿”å›é»˜è®¤å€¼





# æ·»åŠ ä¸€ä¸ªå‡½æ•°æ¥æ˜¾ç¤ºç»“æœï¼Œé¿å…ä»£ç é‡å¤
def display_results(results_df):
    """æ˜¾ç¤ºç›¸ä¼¼åº¦ç»“æœ"""
    if results_df is None or len(results_df) == 0:
        st.warning("âš ï¸ æ²¡æœ‰ç»“æœå¯æ˜¾ç¤º")
        return

    for _, row in results_df.iterrows():
        with st.expander(f"ğŸ”— ç›¸ä¼¼åº¦ {row['Score']}åˆ† - {row.get('Professor Name', 'Unknown')}"):
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown("#### ğŸ‘¨â€ğŸ« æ•™æˆä¿¡æ¯")
                st.write(f"**å§“å:** {row.get('Professor Name', 'N/A')}")
                st.write(f"**èŒä½:** {row.get('Title', 'N/A')}")
                st.write(f"**é™¢ç³»:** {row.get('Department', 'N/A')}")
                st.write(f"**ç½‘å€:** {row['URL']}")
                
                st.markdown("#### ğŸ“– ç ”ç©¶å…´è¶£")
                st.write(row["Research Interests"])
                
                st.markdown("#### ğŸ“Š ç›¸ä¼¼åº¦åˆ†æ")
                st.write(row["Similarity Analysis"])
            
            with col2:
                st.markdown("#### ğŸ·ï¸ å…³é”®è¯")
                keywords = row.get('Keywords', [])
                if keywords and isinstance(keywords, list):
                    for keyword in keywords:
                        st.markdown(render_keyword_tag(keyword), unsafe_allow_html=True)
                else:
                    st.write("æ— å…³é”®è¯")
                
                st.markdown("#### ğŸ“ ç›¸å…³é“¾æ¥")
                additional_urls = row.get('Additional URLs', [])
                if additional_urls and isinstance(additional_urls, list):
                    for url in additional_urls[:3]:  # é™åˆ¶æ˜¾ç¤º3ä¸ªç›¸å…³é“¾æ¥
                        st.markdown(f"[ç›¸å…³é¡µé¢]({url})")
                else:
                    st.write("æ— ç›¸å…³é“¾æ¥")
                
                if row.get('Confidence Score'):
                    st.markdown("#### ğŸ¯ ç½®ä¿¡åº¦")
                    confidence = float(row.get('Confidence Score', 0))
                    st.progress(confidence)
                    st.write(f"{confidence:.1%}")


def display_professor_results(results: list, key_prefix: str = "default"):
    """æ˜¾ç¤ºæ•™æˆåˆ†æç»“æœ"""
    if not results:
        st.warning("âš ï¸ æ²¡æœ‰ç»“æœå¯æ˜¾ç¤º")
        return
        
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(results)
    
    # åˆ†ç¦»æ•™æˆé¡µé¢å’Œéæ•™æˆé¡µé¢
    professor_results = [r for r in results if r.get('Is Professor Page') == 'Yes']
    
    if professor_results:
        st.subheader(f"ğŸ‘¨â€ğŸ« æ‰¾åˆ°çš„æ•™æˆé¡µé¢ ({len(professor_results)}ä½)")
        
        # æ·»åŠ è¿‡æ»¤å’Œæ’åºé€‰é¡¹ - ä½¿ç”¨åŠ¨æ€key
        col1, col2, col3 = st.columns(3)
        with col1:
            confidence_filter = st.slider("æœ€ä½ç½®ä¿¡åº¦", 0.0, 1.0, 0.0, 0.1, key=f"confidence_filter_{key_prefix}")
        with col2:
            sort_by = st.selectbox("æ’åºæ–¹å¼", ["ç½®ä¿¡åº¦", "æ•™æˆå§“å", "é™¢ç³»"], key=f"sort_by_{key_prefix}")
        with col3:
            sort_order = st.selectbox("æ’åºé¡ºåº", ["é™åº", "å‡åº"], key=f"sort_order_{key_prefix}")
        
        # åº”ç”¨è¿‡æ»¤
        filtered_results = [r for r in professor_results if r.get('Confidence Score', 0) >= confidence_filter]
        
        # åº”ç”¨æ’åº
        if sort_by == "ç½®ä¿¡åº¦":
            sort_key = lambda x: x.get('Confidence Score', 0)
        elif sort_by == "æ•™æˆå§“å":
            sort_key = lambda x: x.get('Professor Name', '')
        else:
            sort_key = lambda x: x.get('Department', '')
        
        ascending = (sort_order == "å‡åº")
        filtered_results = sorted(filtered_results, key=sort_key, reverse=not ascending)
        
        # æ˜¾ç¤ºç»“æœ
        for result in filtered_results:
            with st.expander(f"ğŸ‘¨â€ğŸ« {result.get('Professor Name', 'Unknown')} - {result.get('Title', '')}"):
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.markdown("#### ğŸ“ åŸºæœ¬ä¿¡æ¯")
                    st.write(f"**å§“å:** {result.get('Professor Name', 'N/A')}")
                    st.write(f"**èŒä½:** {result.get('Title', 'N/A')}")
                    st.write(f"**é™¢ç³»:** {result.get('Department', 'N/A')}")
                    st.write(f"**ç½‘å€:** {result.get('URL', 'N/A')}")
                    
                    st.markdown("#### ğŸ“– ç ”ç©¶å…´è¶£")
                    research_interests = result.get('Research Interests', '')
                    if research_interests:
                        st.write(research_interests)
                    else:
                        st.write("æœªæ‰¾åˆ°ç ”ç©¶å…´è¶£ä¿¡æ¯")
                
                with col2:
                    st.markdown("#### ğŸ·ï¸ å…³é”®è¯")
                    keywords = result.get('Keywords', [])
                    if keywords and isinstance(keywords, list) and len(keywords) > 0:
                        for keyword in keywords:
                            st.markdown(render_keyword_tag(keyword), unsafe_allow_html=True)
                    else:
                        st.write("æ— å…³é”®è¯")
                    
                    st.markdown("#### ğŸ“ ç›¸å…³é“¾æ¥")
                    additional_urls = result.get('Additional URLs', [])
                    if additional_urls and isinstance(additional_urls, list) and len(additional_urls) > 0:
                        for url in additional_urls[:3]:  # é™åˆ¶æ˜¾ç¤º3ä¸ªç›¸å…³é“¾æ¥
                            st.markdown(f"[ç›¸å…³é¡µé¢]({url})")
                    else:
                        st.write("æ— ç›¸å…³é“¾æ¥")
                    
                    st.markdown("#### ğŸ¯ ç½®ä¿¡åº¦")
                    confidence = result.get('Confidence Score', 0)
                    st.progress(confidence)
                    st.write(f"{confidence:.1%}")
        
        # æä¾›ä¸‹è½½åŠŸèƒ½
        st.markdown("---")
        df_download = pd.DataFrame(professor_results)
        csv_data = df_download.to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½æ•™æˆä¿¡æ¯",
            data=csv_data,
            file_name="professor_analysis_results.csv",
            mime="text/csv",
            key=f"download_button_{key_prefix}"
        )
    else:
        st.warning("âš ï¸ æœªæ‰¾åˆ°æ•™æˆé¡µé¢")
    
    # æ˜¾ç¤ºåˆ†æç»Ÿè®¡
    st.markdown("---")
    st.markdown("#### ğŸ“Š åˆ†æç»Ÿè®¡")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»é“¾æ¥æ•°", len(results))
    with col2:
        st.metric("æ•™æˆé¡µé¢", len(professor_results))
    with col3:
        success_rate = len(professor_results) / len(results) * 100 if results else 0
        st.metric("æˆåŠŸç‡", f"{success_rate:.1f}%")
    with col4:
        avg_confidence = sum(r.get('Confidence Score', 0) for r in professor_results) / len(professor_results) if professor_results else 0
        st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.1%}")


def main():
    st.title("ğŸ“ æ•™æˆç ”ç©¶å…´è¶£åˆ†æå™¨")

    # APIè®¾ç½®åœ¨ä¾§è¾¹æ 
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")
        api_key = st.text_input("è¾“å…¥APIå¯†é’¥ï¼ˆå¿…å¡«ï¼‰", type="password")
        if api_key:
            st.session_state.api_key = api_key
            st.success("âœ… APIå¯†é’¥å·²è®¾ç½®")
        else:
            st.warning("âš ï¸ è¯·è¾“å…¥APIå¯†é’¥æ‰èƒ½ä½¿ç”¨åˆ†æåŠŸèƒ½")

    tab1, tab2 = st.tabs(["ğŸ” ç½‘ç«™åˆ†æ", "ğŸ”„ å…´è¶£åŒ¹é…"])

    with tab1:
        st.header("ğŸ“Š åˆ†æå¤§å­¦ç½‘ç«™ä¸Šçš„æ•™æˆé¡µé¢")

        # åˆ†ææ¨¡å¼é€‰æ‹©
        st.markdown("#### ğŸ¯ åˆ†ææ¨¡å¼")
        analysis_mode = st.radio(
            "é€‰æ‹©åˆ†ææ¨¡å¼:",
            [
                "ğŸ§  æ™ºèƒ½è‡ªé€‚åº”åˆ†æ (æ¨è)",
                "âš™ï¸ æ‰‹åŠ¨å‚æ•°è®¾ç½®",
                "âš¡ å¿«é€Ÿåˆ†æ (é»˜è®¤å‚æ•°)"
            ],
            help="æ™ºèƒ½æ¨¡å¼ä¼šè‡ªåŠ¨åˆ†æé¡µé¢ç‰¹å¾ï¼Œæ¨èæœ€ä¼˜å‚æ•°ï¼Œå¹¶æ ¹æ®ç»“æœåŠ¨æ€è°ƒæ•´æœç´¢ç­–ç•¥"
        )

        if analysis_mode == "ğŸ§  æ™ºèƒ½è‡ªé€‚åº”åˆ†æ (æ¨è)":
            st.info("ğŸ’¡ **æ™ºèƒ½æ¨¡å¼**: ç¨‹åºå°†è‡ªåŠ¨åˆ†æé¡µé¢ç‰¹å¾ï¼Œæ¨èæœ€ä¼˜å‚æ•°ï¼Œå¹¶æ ¹æ®ç»“æœåŠ¨æ€è°ƒæ•´æœç´¢ç­–ç•¥")
            use_intelligent_params = True
            show_manual_params = False
            
        elif analysis_mode == "âš™ï¸ æ‰‹åŠ¨å‚æ•°è®¾ç½®":
            st.info("ğŸ”§ **æ‰‹åŠ¨æ¨¡å¼**: æ‚¨å¯ä»¥è‡ªå®šä¹‰æ‰€æœ‰åˆ†æå‚æ•°")
            use_intelligent_params = False
            show_manual_params = True
            
        else:  # å¿«é€Ÿåˆ†æ
            st.info("âš¡ **å¿«é€Ÿæ¨¡å¼**: ä½¿ç”¨é¢„è®¾çš„é»˜è®¤å‚æ•°è¿›è¡Œåˆ†æ")
            use_intelligent_params = False
            show_manual_params = False

        # åªåœ¨éœ€è¦æ—¶æ˜¾ç¤ºå‚æ•°æ¨èåŠŸèƒ½
        if analysis_mode == "âš™ï¸ æ‰‹åŠ¨å‚æ•°è®¾ç½®":
            col1, col2 = st.columns([2, 1])

            with col1:
                start_url = st.text_input(
                    "è¾“å…¥èµ·å§‹URL", "https://journalism.uiowa.edu/people", key="start_url_manual"
                )

            with col2:
                st.markdown("#### ğŸ§  æ™ºèƒ½å‚æ•°æ¨è")
                if st.button("ğŸ” åˆ†æé¡µé¢å¹¶æ¨èå‚æ•°", key="analyze_params_button"):
                    if start_url:
                        with st.spinner("æ­£åœ¨åˆ†æé¡µé¢ç‰¹å¾..."):
                            try:
                                recommendations = intelligent_parameter_estimation(start_url)
                                
                                st.success("âœ… æ™ºèƒ½åˆ†æå®Œæˆ!")
                                st.info(f"**æ¨èåŸå› **: {recommendations['reasoning']}")
                                
                                # ä¿å­˜æ¨èå‚æ•°åˆ°session state
                                st.session_state.recommended_max_links = recommendations['max_links']
                                st.session_state.recommended_max_pages = recommendations['max_pages']
                                st.session_state.page_analysis = {
                                    'page_type': recommendations.get('page_type', 'unknown'),
                                    'professor_density': recommendations.get('professor_density', 0),
                                    'pagination_detected': recommendations.get('pagination_detected', False)
                                }
                                
                            except Exception as e:
                                st.error(f"æ™ºèƒ½åˆ†æå¤±è´¥: {str(e)}")
        else:
            start_url = st.text_input(
                "è¾“å…¥èµ·å§‹URL", "https://journalism.uiowa.edu/people", key="start_url_default"
            )

        # å‚æ•°è®¾ç½®éƒ¨åˆ† - åªåœ¨æ‰‹åŠ¨æ¨¡å¼ä¸‹æ˜¾ç¤º
        if show_manual_params:
            st.markdown("#### âš™ï¸ åˆ†æå‚æ•°è®¾ç½®")
            
            col3, col4, col5 = st.columns(3)
            
            with col3:
                # æ£€æŸ¥æ˜¯å¦æœ‰æ¨èå‚æ•°
                recommended_links = getattr(st.session_state, 'recommended_max_links', 30)
                max_links = st.number_input(
                    "æœ€å¤§åˆ†æé“¾æ¥æ•°", 
                    min_value=10, 
                    max_value=500, 
                    value=recommended_links, 
                    step=10,
                    help="æ™ºèƒ½æ¨èçš„é“¾æ¥æ•°ï¼Œå¯æ‰‹åŠ¨è°ƒæ•´",
                    key="max_links_manual"
                )
                
            with col4:
                recommended_pages = getattr(st.session_state, 'recommended_max_pages', 3)
                max_pages = st.number_input(
                    "æœ€å¤šè·Ÿéšé¡µæ•°", 
                    min_value=1, 
                    max_value=10, 
                    value=recommended_pages, 
                    step=1,
                    help="æ™ºèƒ½æ¨èçš„é¡µé¢æ•°ï¼Œå¯æ‰‹åŠ¨è°ƒæ•´",
                    key="max_pages_manual"
                )
                
            with col5:
                max_workers = st.number_input(
                    "å·¥ä½œçº¿ç¨‹æ•°", min_value=1, max_value=10, value=5, step=1, key="max_workers_manual"
                )
            
            # æ˜¾ç¤ºé¡µé¢åˆ†æç»“æœ
            if hasattr(st.session_state, 'page_analysis'):
                analysis = st.session_state.page_analysis
                
                st.markdown("#### ğŸ“Š é¡µé¢åˆ†æç»“æœ")
                
                col6, col7, col8 = st.columns(3)
                with col6:
                    page_type_display = {
                        'department': 'ğŸ›ï¸ ç³»çº§é¡µé¢',
                        'college': 'ğŸ« å­¦é™¢çº§é¡µé¢', 
                        'faculty_list': 'ğŸ‘¥ æ•™æˆåˆ—è¡¨',
                        'unknown': 'â“ æœªçŸ¥ç±»å‹'
                    }
                    st.metric("é¡µé¢ç±»å‹", page_type_display.get(analysis['page_type'], 'æœªçŸ¥'))
                    
                with col7:
                    density = analysis.get('professor_density', 0)
                    st.metric("æ•™æˆé“¾æ¥å¯†åº¦", f"{density:.1%}")
                    
                with col8:
                    pagination_status = "âœ… æ£€æµ‹åˆ°" if analysis.get('pagination_detected') else "âŒ æœªæ£€æµ‹åˆ°"
                    st.metric("åˆ†é¡µç»“æ„", pagination_status)
        else:
            # åœ¨æ™ºèƒ½æ¨¡å¼ä¸‹ä»ç„¶æä¾›åŸºæœ¬çš„çº¿ç¨‹æ•°è®¾ç½®
            max_workers = st.number_input(
                "å·¥ä½œçº¿ç¨‹æ•°", min_value=1, max_value=10, value=5, step=1,
                help="å¹¶å‘å¤„ç†çš„çº¿ç¨‹æ•°é‡", key="max_workers_auto"
            )

        if st.button("ğŸš€ å¼€å§‹åˆ†æ", key="start_analysis_button"):
            if not st.session_state.api_key:
                st.error("âŒ è¯·åœ¨ä¾§è¾¹æ è®¾ç½® OpenAI API å¯†é’¥")
            elif not start_url:
                st.error("âŒ è¯·è¾“å…¥èµ·å§‹URL")
            else:
                try:
                    with st.spinner("æ­£åœ¨åˆ†ææ•™æˆé¡µé¢..."):
                        progress_bar = st.progress(0)
                        
                        # æ ¹æ®åˆ†ææ¨¡å¼é€‰æ‹©ä¸åŒçš„å‡½æ•°
                        if analysis_mode == "ğŸ§  æ™ºèƒ½è‡ªé€‚åº”åˆ†æ (æ¨è)":
                            progress_bar.progress(20)
                            
                            results = adaptive_analysis_with_intelligent_params(
                                start_url, 
                                st.session_state.api_key, 
                                max_workers,
                                use_intelligent_params=True
                            )
                            
                        elif analysis_mode == "âš™ï¸ æ‰‹åŠ¨å‚æ•°è®¾ç½®":
                            progress_bar.progress(20)
                            
                            # ç¡®ä¿å‚æ•°å·²å®šä¹‰
                            if 'max_links' not in locals():
                                max_links = getattr(st.session_state, 'recommended_max_links', 30)
                            if 'max_pages' not in locals():
                                max_pages = getattr(st.session_state, 'recommended_max_pages', 3)
                                
                            results = analyze_webpage_links(
                                start_url, 
                                st.session_state.api_key, 
                                max_links, 
                                max_pages, 
                                max_workers
                            )
                            
                        else:  # å¿«é€Ÿåˆ†ææ¨¡å¼
                            progress_bar.progress(20)
                            
                            results = analyze_webpage_links(
                                start_url, 
                                st.session_state.api_key, 
                                30,  # é»˜è®¤é“¾æ¥æ•°
                                3,   # é»˜è®¤é¡µé¢æ•°
                                max_workers
                            )
                        
                        progress_bar.progress(100)
                        
                        if results:
                            st.success(f"âœ… åˆ†æå®Œæˆï¼æ‰¾åˆ° {len(results)} ä¸ªé“¾æ¥")
                            st.session_state.results = results
                            
                            # æ˜¾ç¤ºåˆ†ææ¨¡å¼çš„æ‰§è¡Œç»“æœ
                            if analysis_mode == "ğŸ§  æ™ºèƒ½è‡ªé€‚åº”åˆ†æ (æ¨è)":
                                professor_count = len([r for r in results if r.get('Is Professor Page') == 'Yes'])
                                st.info(f"ğŸ¯ **æ™ºèƒ½åˆ†æç»“æœ**: å‘ç° {professor_count} ä½æ•™æˆï¼Œåˆ†æäº† {len(results)} ä¸ªé“¾æ¥")
                            
                            # æ˜¾ç¤ºç»“æœ
                            display_professor_results(results, key_prefix="tab1_main")
                            
                        else:
                            st.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•ç›¸å…³é“¾æ¥")
                            
                except Exception as e:
                    st.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
                    logger.error(f"Analysis failed: {e}", exc_info=True)
                finally:
                    progress_bar.empty()

        # æ˜¾ç¤ºä¼šè¯ä¸­ä¿å­˜çš„ç»“æœ
        if hasattr(st.session_state, 'results') and st.session_state.results:
            st.subheader("ğŸ“‹ ä¸Šæ¬¡åˆ†æç»“æœ")
            display_professor_results(st.session_state.results, key_prefix="tab1_saved")

    with tab2:
        st.header("ğŸ”„ ç ”ç©¶å…´è¶£ç›¸ä¼¼åº¦åŒ¹é…")

        # æ£€æŸ¥æ˜¯å¦æœ‰æ•™æˆç»“æœ
        professor_results = None
        if hasattr(st.session_state, 'results') and st.session_state.results:
            professor_results = [r for r in st.session_state.results if r.get('Is Professor Page') == 'Yes']
            has_professors = len(professor_results) > 0
        else:
            st.info("â„¹ï¸ è¯·å…ˆåœ¨'ğŸ” ç½‘ç«™åˆ†æ'æ ‡ç­¾ä¸­åˆ†æä¸€ä¸ªç½‘ç«™ä»¥è·å–æ•™æˆç ”ç©¶å…´è¶£")
            professor_results = []
            has_professors = False

        # ç”¨æˆ·è¾“å…¥ç ”ç©¶å…´è¶£
        user_interests = st.text_area(
            "âœï¸ è¾“å…¥æ‚¨çš„ç ”ç©¶å…´è¶£ï¼ˆè¯·è¯¦ç»†æè¿°æ‚¨æ„Ÿå…´è¶£çš„ç ”ç©¶é¢†åŸŸã€æ–¹æ³•å’Œä¸»é¢˜ï¼‰", height=150, key="user_interests_input"
        )
        has_interests = bool(user_interests.strip())

        # å§‹ç»ˆæ˜¾ç¤ºæŒ‰é’®ï¼Œä½†æ ¹æ®æ¡ä»¶ç¦ç”¨
        col1, col2 = st.columns([3, 1])
        with col1:
            calc_button = st.button(
                "ğŸ” è®¡ç®—ç›¸ä¼¼åº¦", disabled=not has_professors or not has_interests, key="calc_similarity_button"
            )
            if not has_professors and not has_interests:
                st.caption("è¯·å…ˆåˆ†æç½‘ç«™å¹¶è¾“å…¥ç ”ç©¶å…´è¶£")
            elif not has_professors:
                st.caption("è¯·å…ˆåˆ†æç½‘ç«™ä»¥è·å–æ•™æˆæ•°æ®")
            elif not has_interests:
                st.caption("è¯·è¾“å…¥æ‚¨çš„ç ”ç©¶å…´è¶£")
        with col2:
            sort_button = st.button(
                "ğŸ“Š æ’åºç»“æœ",
                disabled="similarity_results" not in st.session_state
                or st.session_state.similarity_results is None,
                key="sort_results_button"
            )
            if (
                "similarity_results" not in st.session_state
                or st.session_state.similarity_results is None
            ):
                st.caption("è¯·å…ˆè®¡ç®—ç›¸ä¼¼åº¦")

        # å¤„ç†è®¡ç®—ç›¸ä¼¼åº¦æŒ‰é’®
        if calc_button and has_professors and has_interests:
            if not st.session_state.api_key:
                st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ è®¾ç½®APIå¯†é’¥")
            else:
                st.subheader("ğŸ“Š ç›¸ä¼¼åº¦åˆ†æç»“æœ")

                # æ˜¾ç¤ºè¿›åº¦æŒ‡ç¤ºå™¨
                progress_container = st.empty()
                progress_bar = st.progress(0)
                progress_text = st.empty()

                # ä¸ºæ¯ä½æ•™æˆè®¡ç®—ç›¸ä¼¼åº¦
                results = []
                total_professors = len(professor_results)

                for i, professor in enumerate(professor_results):
                    # æ›´æ–°è¿›åº¦
                    progress = (i) / total_professors
                    progress_bar.progress(progress)
                    progress_text.text(
                        f"â³ æ­£åœ¨è®¡ç®—ç¬¬ {i+1}/{total_professors} ä½æ•™æˆçš„ç›¸ä¼¼åº¦..."
                    )
                    progress_container.info(f"ğŸ”„ åˆ†æä¸­: {professor.get('url', 'Unknown')}")

                    # è®¡ç®—ç›¸ä¼¼åº¦
                    similarity = calculate_similarity(
                        professor.get("research_interests", ""),
                        user_interests,
                        st.session_state.api_key,
                    )
                    # æå–ç›¸ä¼¼åº¦åˆ†æ•°
                    similarity_score = extract_similarity_score(similarity)

                    results.append(
                        {
                            "URL": professor.get("url", ""),
                            "Professor Name": professor.get("professor_name", ""),
                            "Title": professor.get("title", ""),
                            "Department": professor.get("department", ""),
                            "Research Interests": professor.get("research_interests", ""),
                            "Keywords": professor.get("keywords", []),
                            "Additional URLs": professor.get("additional_urls", []),
                            "Confidence Score": professor.get("confidence_score", 0),
                            "Similarity Analysis": similarity,
                            "Score": similarity_score,
                        }
                    )

                # å®Œæˆæ‰€æœ‰è®¡ç®—
                progress_bar.progress(1.0)
                progress_text.text("âœ… ç›¸ä¼¼åº¦è®¡ç®—å®Œæˆ!")
                time.sleep(0.5)  # çŸ­æš‚æ˜¾ç¤ºå®ŒæˆçŠ¶æ€
                progress_bar.empty()
                progress_text.empty()
                progress_container.empty()

                # ä¿å­˜ç»“æœåˆ°ä¼šè¯çŠ¶æ€
                st.session_state.similarity_results = pd.DataFrame(results)

                # æ˜¾ç¤ºç»“æœ
                display_results(st.session_state.similarity_results)

        # å¤„ç†æ’åºæŒ‰é’®
        elif (
            sort_button
            and "similarity_results" in st.session_state
            and st.session_state.similarity_results is not None
        ):
            # æŒ‰ç›¸ä¼¼åº¦åˆ†æ•°æ’åºç»“æœ
            sorted_results = st.session_state.similarity_results.sort_values(
                by="Score", ascending=False
            )

            st.subheader("ğŸ“Š æ’åºåçš„ç›¸ä¼¼åº¦åˆ†æç»“æœ")
            display_professor_results(sorted_results.to_dict(orient='records'), key_prefix="tab2_sorted")

        # å¦‚æœå·²æœ‰ç»“æœä½†æœªç‚¹å‡»ä»»ä½•æŒ‰é’®ï¼Œæ˜¾ç¤ºä¹‹å‰çš„ç»“æœ
        elif (
            "similarity_results" in st.session_state
            and st.session_state.similarity_results is not None
        ):
            st.subheader("ğŸ“Š ä¸Šæ¬¡ç›¸ä¼¼åº¦åˆ†æç»“æœ")
            display_professor_results(st.session_state.similarity_results.to_dict(orient='records'), key_prefix="tab2_saved")


if __name__ == "__main__":
    main()
